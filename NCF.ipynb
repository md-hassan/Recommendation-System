{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import tqdm as tq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import scipy.sparse as sp\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "sys.path.append('/home/shape3d/code/RecSys/Recommendation System')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all():\n",
    "\ttrain_data = pd.read_csv(\n",
    "\t\t'data/ml-1m.train.rating', \n",
    "\t\tsep='\\t', header=None, names=['user', 'item'], \n",
    "\t\tusecols=[0, 1], dtype={0: np.int32, 1: np.int32})\n",
    "\n",
    "\tuser_num = train_data['user'].max() + 1\n",
    "\titem_num = train_data['item'].max() + 1\n",
    "\n",
    "\ttrain_data = train_data.values.tolist()\n",
    "\n",
    "\ttrain_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
    "\tfor x in train_data:\n",
    "\t\ttrain_mat[x[0], x[1]] = 1.0\n",
    "\n",
    "\ttest_data = []\n",
    "\twith open('data/ml-1m.test.negative', 'r') as fd:\n",
    "\t\tline = fd.readline()\n",
    "\t\twhile line != None and line != '':\n",
    "\t\t\tarr = line.split('\\t')\n",
    "\t\t\tu = eval(arr[0])[0]\n",
    "\t\t\ttest_data.append([u, eval(arr[0])[1]])\n",
    "\t\t\tfor i in arr[1:]:\n",
    "\t\t\t\ttest_data.append([u, int(i)])\n",
    "\t\t\tline = fd.readline()\n",
    "\treturn train_data, test_data, user_num, item_num, train_mat\n",
    "\n",
    "train_data, test_data, user_num ,item_num, train_mat = load_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetClass(data.Dataset):\n",
    "    def __init__(self, features, num_item, train_mat = None, num_ng = 0, is_training = None):\n",
    "        super(DatasetClass, self).__init__()\n",
    "        self.features_ps = features\n",
    "        self.num_item = num_item\n",
    "        self.train_mat = train_mat\n",
    "        self.num_ng = num_ng\n",
    "        self.is_training = is_training\n",
    "        self.labels = [0 for _ in range(len(features))]\n",
    "\n",
    "    def ng_sample(self):\n",
    "        self.features_ng = []\n",
    "        for x in self.features_ps:\n",
    "            u = x[0]\n",
    "            for t in range(self.num_ng):\n",
    "                j = np.random.randint(self.num_item)\n",
    "                while (u, j) in self.train_mat:\n",
    "                    j = np.random.randint(self.num_item)\n",
    "                self.features_ng.append([u, j])\n",
    "\n",
    "        labels_ps = [1 for _ in range(len(self.features_ps))]\n",
    "        labels_ng = [0 for _ in range(len(self.features_ng))]\n",
    "\n",
    "        self.features_fill = self.features_ps + self.features_ng\n",
    "        self.labels_fill = labels_ps + labels_ng\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_ng + 1) * len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features_fill if self.is_training else self.features_ps\n",
    "        labels = self.labels_fill if self.is_training else self.labels\n",
    "\n",
    "        user = features[idx][0]\n",
    "        item = features[idx][1]\n",
    "        label = labels[idx]\n",
    "        return user, item ,label\n",
    "\t\t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetClass(train_data, item_num, train_mat, 4, True)\n",
    "test_dataset = DatasetClass(test_data, item_num, train_mat, 0, False)\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size = 256, shuffle=True)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size = 100, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, user_num, item_num, factor_num, num_layers = 3):\n",
    "        super(NCF, self).__init__()\n",
    "\n",
    "        self.embed_user_GMF = nn.Embedding(user_num, factor_num)\n",
    "        self.embed_item_GMF = nn.Embedding(item_num, factor_num)\n",
    "        self.embed_user_MLP = nn.Embedding(\n",
    "                user_num, factor_num * (2 ** (num_layers - 1)))\n",
    "        self.embed_item_MLP = nn.Embedding(\n",
    "                item_num, factor_num * (2 ** (num_layers - 1)))\n",
    "\n",
    "        MLP_modules = []\n",
    "        for i in range(num_layers):\n",
    "            input_size = factor_num * (2 ** (num_layers - i))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size//2))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "\n",
    "        predict_size = factor_num * 2\n",
    "        self.predict_layer = nn.Linear(predict_size, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        embed_user_GMF = self.embed_user_GMF(user)\n",
    "        embed_item_GMF = self.embed_item_GMF(item)\n",
    "        output_GMF = embed_user_GMF * embed_item_GMF\n",
    "\n",
    "        embed_user_MLP = self.embed_user_MLP(user)\n",
    "        embed_item_MLP = self.embed_item_MLP(item)\n",
    "        interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n",
    "        output_MLP = self.MLP_layers(interaction)\n",
    "\n",
    "        concat = torch.cat((output_GMF, output_MLP), -1)\n",
    "\n",
    "        prediction = self.predict_layer(concat)\n",
    "        return prediction.view(-1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NCF(user_num, item_num, factor_num = 16)\n",
    "model.cuda()\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define metrics and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def ndcg(gt_item, pred_items):\n",
    "\tif gt_item in pred_items:\n",
    "\t\tindex = pred_items.index(gt_item)\n",
    "\t\treturn np.reciprocal(np.log2(index+2))\n",
    "\treturn 0\n",
    "\n",
    "def validation(model, test_loader, top_k):\n",
    "\tHR_10, HR_1, NDCG_10, NDCG_1 = [], [], [], []\n",
    "\n",
    "\tfor user, item, label in test_loader:\n",
    "\t\tuser = user.cuda()\n",
    "\t\titem = item.cuda()\n",
    "\n",
    "\t\tpredictions = model(user, item)\n",
    "\t\t_, indices = torch.topk(predictions, top_k)\n",
    "\t\trecommends = torch.take(\n",
    "\t\t\t\titem, indices).cpu().numpy().tolist()\n",
    "\n",
    "\t\tgt_item = item[0].item()\n",
    "\t\tHR_10.append(hit(gt_item, recommends))\n",
    "\t\tHR_1.append(hit(gt_item, [recommends[0]]))\n",
    "\t\tNDCG_10.append(ndcg(gt_item, recommends))\n",
    "\t\tNDCG_1.append(ndcg(gt_item, [recommends[0]]))\n",
    "\n",
    "\treturn np.mean(HR_10), np.mean(HR_1), np.mean(NDCG_10), np.mean(NDCG_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('log') # start tensorboard\n",
    "for f in os.listdir('log'):\n",
    "    os.remove('log/' + f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [01:14<48:15, 74.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.454\tNDCG@10: 0.252\tNDCG@1: 0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [02:28<46:55, 74.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.463\tNDCG@10: 0.258\tNDCG@1: 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [03:42<45:49, 74.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.494\tNDCG@10: 0.273\tNDCG@1: 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [04:56<44:23, 73.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.526\tNDCG@10: 0.292\tNDCG@1: 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [06:10<43:17, 74.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.557\tNDCG@10: 0.310\tNDCG@1: 0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [07:25<42:05, 74.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.571\tNDCG@10: 0.321\tNDCG@1: 0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [08:39<40:49, 74.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.600\tNDCG@10: 0.336\tNDCG@1: 0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [09:53<39:32, 74.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.616\tNDCG@10: 0.345\tNDCG@1: 0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [11:07<38:16, 74.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.617\tNDCG@10: 0.352\tNDCG@1: 0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [12:21<37:00, 74.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.635\tNDCG@10: 0.365\tNDCG@1: 0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [13:34<35:43, 73.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.637\tNDCG@10: 0.371\tNDCG@1: 0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [14:48<34:23, 73.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.642\tNDCG@10: 0.372\tNDCG@1: 0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [16:01<33:06, 73.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.652\tNDCG@10: 0.380\tNDCG@1: 0.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [17:15<31:54, 73.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.663\tNDCG@10: 0.389\tNDCG@1: 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [18:28<30:35, 73.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.662\tNDCG@10: 0.390\tNDCG@1: 0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [19:42<29:27, 73.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.667\tNDCG@10: 0.397\tNDCG@1: 0.180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [20:55<28:11, 73.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.669\tNDCG@10: 0.396\tNDCG@1: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [22:09<27:03, 73.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.668\tNDCG@10: 0.398\tNDCG@1: 0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [23:23<25:49, 73.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.677\tNDCG@10: 0.405\tNDCG@1: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [24:38<24:41, 74.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.674\tNDCG@10: 0.402\tNDCG@1: 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [25:51<23:23, 73.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.674\tNDCG@10: 0.404\tNDCG@1: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [27:05<22:07, 73.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.678\tNDCG@10: 0.406\tNDCG@1: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [28:18<20:50, 73.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.681\tNDCG@10: 0.407\tNDCG@1: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [29:32<19:41, 73.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.677\tNDCG@10: 0.408\tNDCG@1: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [30:46<18:25, 73.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.677\tNDCG@10: 0.408\tNDCG@1: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [32:00<17:15, 74.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.682\tNDCG@10: 0.412\tNDCG@1: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [33:14<15:59, 73.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.679\tNDCG@10: 0.410\tNDCG@1: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [34:28<14:46, 73.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.682\tNDCG@10: 0.413\tNDCG@1: 0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [35:41<13:30, 73.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.682\tNDCG@10: 0.413\tNDCG@1: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [36:55<12:18, 73.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.684\tNDCG@10: 0.412\tNDCG@1: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [38:09<11:04, 73.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.683\tNDCG@10: 0.411\tNDCG@1: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [39:21<09:47, 73.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.684\tNDCG@10: 0.413\tNDCG@1: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [40:35<08:34, 73.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.683\tNDCG@10: 0.408\tNDCG@1: 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [41:49<07:20, 73.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.688\tNDCG@10: 0.414\tNDCG@1: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [43:02<06:07, 73.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.678\tNDCG@10: 0.407\tNDCG@1: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [44:15<04:52, 73.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.677\tNDCG@10: 0.406\tNDCG@1: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [45:20<03:32, 70.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.682\tNDCG@10: 0.410\tNDCG@1: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [46:26<02:18, 69.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.680\tNDCG@10: 0.410\tNDCG@1: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [47:31<01:08, 68.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.684\tNDCG@10: 0.410\tNDCG@1: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [48:37<00:00, 72.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.682\tNDCG@10: 0.412\tNDCG@1: 0.189\n",
      "End. Best epoch 033: HR@10 = 0.688, NDCG@10 = 0.414 NDCG@1 = 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "\n",
    "def train_loop():\n",
    "\tcount, best_ndcg_10 = 0, 0\n",
    "\tfor epoch in tq.tqdm(range(epochs)):\n",
    "\t\tmodel.train()\n",
    "\t\ttrain_dataloader.dataset.ng_sample()\n",
    "\n",
    "\t\tepoch_loss = 0\n",
    "\t\tfor user, item, label in train_dataloader:\n",
    "\t\t\tuser = user.cuda()\n",
    "\t\t\titem = item.cuda()\n",
    "\t\t\tlabel = label.float().cuda()\n",
    "\n",
    "\t\t\tmodel.zero_grad()\n",
    "\t\t\tprediction = model(user, item)\n",
    "\t\t\tloss = loss_function(prediction, label)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\twriter.add_scalar('Iteration loss', loss.item(), count)\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\t\tcount += 1\n",
    "\n",
    "\t\tmodel.eval()\n",
    "\t\tHR_10, HR_1, NDCG_10, NDCG_1 = validation(model, test_dataloader, top_k = 10)\n",
    "\t\twriter.add_scalar('Epoch loss', epoch_loss/len(train_dataloader), epoch)\n",
    "\t\twriter.add_scalar('HR@10', HR_10, epoch)\n",
    "\t\twriter.add_scalar('HR@1', HR_1, epoch)\n",
    "\t\twriter.add_scalar('NDCG@10', NDCG_10, epoch)\n",
    "\t\twriter.add_scalar('NDCG@1', NDCG_1, epoch)\n",
    "\n",
    "\t\tprint(\"HR: {:.3f}\\tNDCG@10: {:.3f}\\tNDCG@1: {:.3f}\".format(np.mean(HR_10), np.mean(NDCG_10), np.mean(NDCG_1)))\n",
    "\n",
    "\t\tif NDCG_10 > best_ndcg_10:\n",
    "\t\t\tbest_hr, best_ndcg_10, best_ndcg_1, best_epoch = HR_10, NDCG_10, NDCG_1, epoch\n",
    "\t\t\ttorch.save(model, 'ckpt/best_NDCG.pth')\n",
    "\n",
    "\tprint(\"End. Best epoch {:03d}: HR@10 = {:.3f}, NDCG@10 = {:.3f} NDCG@1 = {:.3f}\".format(best_epoch, best_hr, best_ndcg_10, best_ndcg_1))\n",
    "\n",
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
